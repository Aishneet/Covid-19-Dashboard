{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "\n",
    "%matplotlib inline\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "from plotly.subplots import make_subplots\n",
    "import cufflinks as cf\n",
    "from plotly.offline import init_notebook_mode,plot,iplot \n",
    "\n",
    "import folium # for maps\n",
    "\n",
    "from zipfile import ZipFile \n",
    "import seaborn as sns\n",
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "#import geopandas as gpd\n",
    "import os\n",
    "import kaggle\n",
    "from time import time,sleep\n",
    "from random import randint\n",
    "from IPython.core.display import clear_output\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen as uReq\n",
    "import lxml.html as lh\n",
    "import requests\n",
    "from fbprophet import Prophet\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyo.init_notebook_mode(connected=True)\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases_india=0\n",
    "recover_cases_india=0\n",
    "death_cases_india=0\n",
    "active_cases_india=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata():\n",
    "    url = 'https://www.mohfw.gov.in/' \n",
    "\n",
    "        # make a GET request to fetch the raw HTML content\n",
    "    web_content = requests.get(url).content\n",
    "\n",
    "        # parse the html content\n",
    "    soup = BeautifulSoup(web_content, \"html.parser\")\n",
    "\n",
    "        # remove any newlines and extra spaces from left and right\n",
    "    extract_contents = lambda row: [x.text.replace('\\n', '') for x in row] \n",
    "\n",
    "    stats = [] # initialize stats\n",
    "    all_rows = soup.find_all('tr') # find all table rows \n",
    "\n",
    "    for row in all_rows: \n",
    "        stat = extract_contents(row.find_all('td')) # find all data cells  \n",
    "            # notice that the data that we require is now a list of length 5\n",
    "        if len(stat) == 5: \n",
    "            stats.append(stat)\n",
    "\n",
    "        # now convert the data into a pandas dataframe for further processing\n",
    "    new_cols = [\"Sr.No\", \"States/UT\",\"Confirmed\",\"Recovered\",\"Deceased\"]\n",
    "    state_data = pd.DataFrame(data = stats, columns = new_cols)\n",
    "    state_data = state_data.iloc[:35,:]\n",
    "    print(state_data)\n",
    "    return state_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images():\n",
    "    state_data = getdata()\n",
    "    dec=[]\n",
    "\n",
    "    for x in state_data['Deceased']:\n",
    "        x = x.replace('#','')\n",
    "        x = x.replace('*','')\n",
    "        dec.append(x)\n",
    "    state_data['Deceased']=dec\n",
    "    dec.clear()\n",
    "\n",
    "    for x in state_data['Confirmed']:\n",
    "        x = x.replace('#','')\n",
    "        x = x.replace('*','')\n",
    "        dec.append(x)\n",
    "    state_data['Confirmed']=dec\n",
    "    dec.clear()\n",
    "\n",
    "    for x in state_data['Recovered']:\n",
    "        x = x.replace('#','')\n",
    "        x = x.replace('*','')\n",
    "        dec.append(x)\n",
    "    state_data['Recovered']=dec\n",
    "    dec.clear()\n",
    "\n",
    "    for x in state_data['States/UT']:\n",
    "        x = x.replace('#','')\n",
    "        x = x.replace('*','')\n",
    "        dec.append(x)\n",
    "    state_data['States/UT']=dec\n",
    "    dec.clear()\n",
    "\n",
    "\n",
    "    # converting the 'string' data to 'int'\n",
    "    state_data['Confirmed'] = state_data['Confirmed'].map(int)\n",
    "    state_data['Recovered'] = state_data['Recovered'].map(int)\n",
    "    state_data['Deceased']  = state_data['Deceased'].map(int)\n",
    "    total_cases_india=state_data['Confirmed'].sum()\n",
    "    recover_cases_india=state_data['Recovered'].sum()\n",
    "    death_cases_india=state_data['Deceased'].sum()\n",
    "    state_data['Active Cases']=state_data['Confirmed']-(state_data['Deceased']+state_data['Recovered'])\n",
    "    active_cases_india = state_data['Active Cases'].sum()\n",
    "    cases_in_India = [total_cases_india,recover_cases_india,death_cases_india]\n",
    "    #plot1\n",
    "    state_data.sort_values(\"Confirmed\",ascending=False,inplace=True)\n",
    "    fig = px.bar(state_data,x='States/UT',y='Confirmed',color='Confirmed',width=700, height=500,text='Confirmed',title=\"Confirmed Covid19 Cases in Indian States\")\n",
    "    fig.write_html(\"static/india_state_confirm_case.html\")\n",
    "    \n",
    "    #plot2\n",
    "    state_data.sort_values(\"Active Cases\",ascending=False,inplace=True)\n",
    "    fig = px.bar(state_data,x='States/UT',y='Active Cases',color='Active Cases',width=700,height = 500,text='Active Cases')\n",
    "    fig.update_layout(title=\"Active Cases in Indian States\")\n",
    "    fig.write_html(\"static/india_state_active_case.html\")\n",
    "    \n",
    "    \n",
    "    #plot3\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=state_data['States/UT'], y=state_data['Confirmed'],mode='lines+markers',name='Confirmed Cases in each state',showlegend=True))\n",
    "    fig.add_trace(go.Scatter(x=state_data['States/UT'], y=state_data['Deceased'],mode='lines+markers',name='Deaths Cases in each state',showlegend=True))\n",
    "    fig.add_trace(go.Scatter(x=state_data['States/UT'], y=state_data['Recovered'],mode='lines+markers',name='Recovered Cases in each state',showlegend=True))\n",
    "    fig.update_layout(title=\"All State Analysis\",xaxis_title=\"States/UT\",yaxis_title=\"Number of people\")\n",
    "    #fig.show()\n",
    "    fig.write_html(\"static/india_states_analysis.html\")\n",
    "    \n",
    "    #dataset\n",
    "    f = open(\"indiageodata.json\")\n",
    "    counties = json.load(f)\n",
    "    \n",
    "    #plot4\n",
    "    fig = px.choropleth_mapbox(state_data, geojson=counties, locations='States/UT', color='Active Cases',\n",
    "                               color_continuous_scale=\"Viridis\",featureidkey=\"properties.NAME_1\",\n",
    "                           mapbox_style=\"carto-positron\",hover_data=[\"Confirmed\", \"Active Cases\",\"Recovered\",\"Deceased\"],\n",
    "                               zoom=3,center = {\"lat\": 20.5937, \"lon\": 78.9629},opacity=0.5,\n",
    "                               labels={'Active Cases':'Active Cases'})\n",
    "    fig.write_html('static/india_covidcases_map.html')\n",
    "    \n",
    "    \n",
    "    #webscrap world corona cases\n",
    "    import requests\n",
    "    req = requests.get(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n",
    "    url_content = req.content\n",
    "    csv_file = open(r'owid-covid-data.csv','wb')\n",
    "\n",
    "    csv_file.write(url_content)\n",
    "    csv_file.close()\n",
    "    data = pd.read_csv(r'owid-covid-data.csv',parse_dates=True)\n",
    "    data_italy = data[(data.location=='Italy')]\n",
    "    data_us = data[(data.location=='United States')]\n",
    "    data_india = data[(data.location=='India')]\n",
    "    data_china = data[(data.location=='China')]\n",
    "    \n",
    "    \n",
    "    #plot6\n",
    "    fig=make_subplots(\n",
    "    rows=2,cols=2,\n",
    "    specs=[[{\"secondary_y\":True},{\"secondary_y\":True}],[{\"secondary_y\":True},{\"secondary_y\":True}]],\n",
    "    subplot_titles=(\"China\",\"Italy\",\"United States\",\"India\"))\n",
    "\n",
    "    fig.add_trace(go.Bar(x=data_china['date'],y=data_china['total_cases'],\n",
    "                        marker=dict(color=data_china['total_cases'],coloraxis=\"coloraxis\")),1,1)\n",
    "\n",
    "    fig.add_trace(go.Bar(x=data_italy['date'],y=data_italy['total_cases'],\n",
    "                        marker=dict(color=data_italy['total_cases'],coloraxis=\"coloraxis\")),1,2)\n",
    "\n",
    "    fig.add_trace(go.Bar(x=data_us['date'],y=data_us['total_cases'],\n",
    "                        marker=dict(color=data_us['total_cases'],coloraxis=\"coloraxis\")),2,1)\n",
    "\n",
    "    fig.add_trace(go.Bar(x=data_india['date'],y=data_india['total_cases'],\n",
    "                        marker=dict(color=data_india['total_cases'],coloraxis=\"coloraxis\")),2,2)\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_layout(showlegend=False,title_text=\"Total Cases in 4 Countries\",xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Number of people\")\n",
    "\n",
    "    fig.update_layout(plot_bgcolor='rgb(169,169,169)')\n",
    "    fig.write_html(\"static/country_comparision_total_cases.html\")\n",
    "\n",
    "    #data\n",
    "    !kaggle datasets download -d sudalairajkumar/novel-corona-virus-2019-dataset --force\n",
    "    file_name = \"novel-corona-virus-2019-dataset.zip\"\n",
    "    # opening the zip file in READ mode \n",
    "    with ZipFile(file_name, 'r') as zip: \n",
    "        # extracting the file \n",
    "        zip.extract(\"covid_19_data.csv\")\n",
    "        zip.extract(\"time_series_covid_19_confirmed.csv\")\n",
    "    df=pd.read_csv(r'covid_19_data.csv',parse_dates=['Last Update'])\n",
    "    df.rename(columns={'ObservationDate':'Date','Country/Region':'Country'},inplace=True)\n",
    "    confirmed=df.groupby('Date').sum()['Confirmed'].reset_index()\n",
    "    death=df.groupby('Date').sum()['Deaths'].reset_index()\n",
    "    rec=df.groupby('Date').sum()['Recovered'].reset_index()\n",
    "    \n",
    "    #plot7\n",
    "    fig=go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=confirmed['Date'],y=confirmed['Confirmed'],mode='lines+markers',name='Confirmed',line=dict(color='blue',width=2)))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=death['Date'],y=death['Deaths'],mode='lines+markers',name='Deaths',line=dict(color='red',width=2)))\n",
    "    fig.add_trace(go.Scatter(x=rec['Date'],y=rec['Recovered'],mode='lines+markers',name='Recovered',line=dict(color='green',width=2)))\n",
    "    fig.update_layout(title_text=\"covid 19 cases in world\",xaxis_title='Observation Date' ,yaxis_title='number of people')\n",
    "    fig.write_html(\"static/world_confirm_death_cured.html\")\n",
    "    \n",
    "    #data\n",
    "    df_confirmed=pd.read_csv(r'time_series_covid_19_confirmed.csv')\n",
    "    df_confirmed.rename(columns={'Country/Region':'Country'},inplace=True)\n",
    "    df_latlong=pd.merge(df,df_confirmed,on=['Country','Province/State'])\n",
    "    \n",
    "    \n",
    "    #plot9\n",
    "    fig=px.scatter_mapbox(df_latlong,lat=\"Lat\",lon=\"Long\",zoom=1,height=700)\n",
    "    fig.update_layout(title='Worldwide Corona Virus Cases')\n",
    "    fig.update_layout(mapbox_style=\"carto-positron\",mapbox_center_lon=0)\n",
    "    fig.update_layout(margin={\"r\":2,\"t\":50,\"l\":2,\"b\":0},xaxis_title = \"Observation Date\",yaxis_title='Corona Cases')\n",
    "    fig.write_html(\"static/world_cases_scatter_plot.html\")\n",
    "   \n",
    "    return total_cases_india,recover_cases_india,death_cases_india,active_cases_india  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "  url = 'https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
    "  url_cnf = 'https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "  # for confirmed cases overall\n",
    "  cnf = uReq(url_cnf)\n",
    "  pg_cnf = requests.get(url_cnf)\n",
    "  doc_cnf = lh.fromstring(pg_cnf.content)\n",
    "  cnf_elements = doc_cnf.xpath('//tr')\n",
    "  cnf.close()\n",
    "  # for deaths overall\n",
    "  client = uReq(url)\n",
    "  page = requests.get(url)\n",
    "  doc = lh.fromstring(page.content)\n",
    "  tr_elements = doc.xpath('//tr')\n",
    "  client.close()\n",
    "  # for confirmed cases\n",
    "  col_cnf=[]\n",
    "  i=0\n",
    "  #For each row, store each first element (header) and an empty list\n",
    "  for t in cnf_elements[0]:\n",
    "      i+=1\n",
    "      name=t.text_content()\n",
    "      #print ('%d:\"%s\"'%(i,name))\n",
    "      col_cnf.append((name,[]))\n",
    "  # for deaths\n",
    "  col=[]\n",
    "  i=0\n",
    "  #For each row, store each first element (header) and an empty list\n",
    "  for t in tr_elements[0]:\n",
    "      i+=1\n",
    "      name=t.text_content()\n",
    "      #print ('%d:\"%s\"'%(i,name))\n",
    "      col.append((name,[]))\n",
    "  # for confirmed cases\n",
    "\n",
    "  for j in range(1,len(cnf_elements)):\n",
    "    T=cnf_elements[j]\n",
    "    i=0\n",
    "    for t in T.iterchildren():\n",
    "          data=t.text_content() \n",
    "          if i>0:\n",
    "          #Convert any numerical value to integers\n",
    "              try:\n",
    "                  data=int(data)\n",
    "              except:\n",
    "                  pass\n",
    "          #Append the data to the empty list of the i'th column\n",
    "          col_cnf[i][1].append(data)\n",
    "          #Increment i for the next column\n",
    "          i+=1\n",
    "    # for deaths \n",
    "\n",
    "  for j in range(1,len(tr_elements)):\n",
    "    T=tr_elements[j]\n",
    "    i=0\n",
    "    for t in T.iterchildren():\n",
    "          data=t.text_content() \n",
    "          if i>0:\n",
    "          #Convert any numerical value to integers\n",
    "              try:\n",
    "                  data=int(data)\n",
    "              except:\n",
    "                  pass\n",
    "          #Append the data to the empty list of the i'th column\n",
    "          col[i][1].append(data)\n",
    "          #Increment i for the next column\n",
    "          i+=1\n",
    "\n",
    "  Dict={title:column for (title,column) in col}\n",
    "  df=pd.DataFrame(Dict)\n",
    "  d={title:column for (title,column) in col_cnf}\n",
    "  cnf=pd.DataFrame(d)\n",
    "  cnf.to_csv('time_series_cnf.csv')\n",
    "  cnf.rename(columns={'Country/Region':'Country'}, inplace=True)\n",
    "  col = ['Country','Lat','Long','Province/State']\n",
    "  cnf_india = cnf[cnf['Country'] == 'India'].drop(col,axis = 1).transpose().reset_index().drop(0,axis = 0)\n",
    "\n",
    "  cnf_india.rename(columns = {'index':'Date'}, inplace = True) \n",
    "  cnf_india.rename(columns = {131:'Confirmed'}, inplace = True) \n",
    "  fin_cnf = cnf_india\n",
    "  index = fin_cnf.index\n",
    "  length = len(index)\n",
    "  for i in range(1,length+1):\n",
    "    fin_cnf['Date'][i] = str(fin_cnf['Date'][i])\n",
    "    fin_cnf['Confirmed'][i] = (fin_cnf['Confirmed'][i])\n",
    "  fin_cnf.columns = ['ds','y']\n",
    "  fin_cnf['ds'] = pd.to_datetime(fin_cnf['ds'])\n",
    "  type(fin_cnf['ds'])\n",
    "  confirmed = fin_cnf\n",
    "\n",
    "  m = Prophet(interval_width=0.95,yearly_seasonality=True,daily_seasonality=True)\n",
    "  m.fit(confirmed)\n",
    "  future = m.make_future_dataframe(periods=7)\n",
    "  future.tail()\n",
    "  forecast = m.predict(future)\n",
    "  forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "\n",
    "  df.rename(columns={'Country/Region':'Country'}, inplace=True)\n",
    "  col = ['Country','Lat','Long','Province/State']\n",
    "  df =  df[df['Country'] == 'India'].drop(col,axis = 1).transpose().reset_index().drop(0,axis = 0)\n",
    "\n",
    "  df.rename(columns = {'index':'Date'}, inplace = True) \n",
    "  df.rename(columns = {131:'Death'}, inplace = True) \n",
    "\n",
    "  fin_df = df\n",
    "  index = df.index\n",
    "  length = len(index)\n",
    "  for i in range(1,length+1):\n",
    "    fin_df['Date'][i] = str(df['Date'][i])\n",
    "    fin_df['Death'][i] = (df['Death'][i])\n",
    "\n",
    "  fin_df.columns = ['ds','y']\n",
    "  fin_df['ds'] = pd.to_datetime(fin_cnf['ds'])\n",
    "\n",
    "  confirm = fin_df\n",
    "\n",
    "  m = Prophet(interval_width=0.95,yearly_seasonality=True,daily_seasonality=True)\n",
    "  m.fit(confirm)\n",
    "  future_death = m.make_future_dataframe(periods=7)\n",
    "  future_death.tail()\n",
    "  forecast_death = m.predict(future)\n",
    "  \n",
    "\n",
    "\n",
    "  index = forecast_death.index\n",
    "  length1 = len(index)\n",
    "\n",
    "  death = []\n",
    "  conf = []\n",
    "\n",
    "  for i in range(length,length1):\n",
    "    death.append(forecast_death['yhat_lower'][i])\n",
    "    conf.append(forecast['yhat_lower'][i])\n",
    "  \n",
    "  forecast_death_7 = forecast_death.loc[length:len(forecast),['ds','yhat_lower']]\n",
    "  forecast_cnf_7 = forecast.loc[length:len(forecast),['ds','yhat_lower']]\n",
    "  forecast_death_7.to_csv('death_7.csv')\n",
    "  forecast_cnf_7.to_csv('conf_7.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask_ngrok import run_with_ngrok\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sr.No                    States/UT Confirmed Recovered Deceased\n",
      "0      1  Andaman and Nicobar Islands        33        33        0\n",
      "1      2               Andhra Pradesh      3251      2125       59\n",
      "2      3            Arunachal Pradesh         3         1        0\n",
      "3      4                        Assam       856       104        4\n",
      "4      5                        Bihar      3296      1211       15\n",
      "5      6                   Chandigarh       288       189        4\n",
      "6      7                 Chhattisgarh       399        83        0\n",
      "7      8           Dadar Nagar Haveli         2         0        0\n",
      "8      9                        Delhi     16281      7495      316\n",
      "9     10                          Goa        69        38        0\n",
      "10    11                      Gujarat     15562      8003      960\n",
      "11    12                      Haryana      1504       881       19\n",
      "12    13             Himachal Pradesh       276        70        5\n",
      "13    14            Jammu and Kashmir      2036       859       27\n",
      "14    15                    Jharkhand       469       212        4\n",
      "15    16                    Karnataka      2533       834       47\n",
      "16    17                       Kerala      1088       555        7\n",
      "17    18                       Ladakh        73        43        0\n",
      "18    19               Madhya Pradesh      7453      4050      321\n",
      "19    20                  Maharashtra     59546     18616     1982\n",
      "20    21                      Manipur        55         5        0\n",
      "21    22                    Meghalaya        21        12        1\n",
      "22    23                      Mizoram         1         1        0\n",
      "23    24                     Nagaland        18         0        0\n",
      "24    25                       Odisha      1660       887        7\n",
      "25    26                   Puducherry        51        14        0\n",
      "26    27                       Punjab      2158      1946       40\n",
      "27    28                    Rajasthan      8067      4817      180\n",
      "28    29                       Sikkim         1         0        0\n",
      "29    30                   Tamil Nadu     19372     10548      145\n",
      "30    31                    Telengana      2256      1345       67\n",
      "31    32                      Tripura       242       167        0\n",
      "32    33                  Uttarakhand       500        79        4\n",
      "33    34                Uttar Pradesh      7170      4215      197\n",
      "34    35                  West Bengal      4536      1668      295\n",
      "Downloading novel-corona-virus-2019-dataset.zip to C:\\Users\\Akshat\\Desktop\\dataset used\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/1.11M [00:00<?, ?B/s]\n",
      " 90%|########9 | 1.00M/1.11M [00:00<00:00, 5.26MB/s]\n",
      "100%|##########| 1.11M/1.11M [00:00<00:00, 5.62MB/s]\n"
     ]
    }
   ],
   "source": [
    "total_cases_india,recover_cases_india,death_cases_india,active_cases_india = images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "death_pred = pd.read_csv(\"death_7.csv\")\n",
    "conf_pred = pd.read_csv(\"conf_7.csv\")\n",
    "conf_pred.drop(conf_pred.columns[[0]], axis = 1, inplace = True)\n",
    "conf_pred.rename(columns = {\"ds\": \"Date\", \"yhat_lower\":\"Predicted Cases\"}, inplace = True)\n",
    "death_pred.drop(death_pred.columns[[0]], axis = 1, inplace = True)\n",
    "death_pred.rename(columns = {\"ds\": \"Date\", \"yhat_lower\":\"Predicted Cases\"}, inplace = True)\n",
    "conf_pred['Predicted Cases'] = conf_pred['Predicted Cases'].map(int)\n",
    "death_pred['Predicted Cases'] = death_pred['Predicted Cases'].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Running on http://8dde834c6894.ngrok.io\n",
      " * Traffic stats available on http://127.0.0.1:4040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [29/May/2020 12:11:34] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/May/2020 12:11:34] \"GET /static/default.css HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/May/2020 12:11:34] \"GET /static/fonts.css HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/May/2020 12:11:34] \"GET /static/images/COV19.jpg HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/May/2020 12:11:34] \"GET /static/india_states_analysis.html HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/May/2020 12:11:34] \"GET /static/india_state_confirm_case.html HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/May/2020 12:11:34] \"GET /static/india_state_active_case.html HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [29/May/2020 12:11:36] \"GET /static/india_covidcases_map.html HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask_ngrok import run_with_ngrok\n",
    "\n",
    "\n",
    "\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "run_with_ngrok(app)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html',total_cases=total_cases_india, recovered_cases = recover_cases_india,death_cases=death_cases_india,active_cases=active_cases_india)\n",
    "\n",
    "@app.route('/india')\n",
    "def india():\n",
    "    return render_template('index.html',total_cases=total_cases_india, recovered_cases = recover_cases_india,death_cases=death_cases_india,active_cases=active_cases_india)\n",
    "\n",
    "\n",
    "@app.route('/worlddata')\n",
    "def worlddata():\n",
    "    return render_template('worldcase.html')\n",
    "\n",
    "\n",
    "@app.route('/info')\n",
    "def info():\n",
    "    return render_template('info.html')\n",
    "\n",
    "@app.route('/confirmcase')\n",
    "def confirmcase():\n",
    "    return render_template('predicted_confirm_cases.html',  tables=[conf_pred.to_html(classes='data')])\n",
    "\n",
    "@app.route('/deathcase')\n",
    "def deathcase():\n",
    "    return render_template('predicted_death_cases.html',  tables=[death_pred.to_html(classes='data')])\n",
    "\n",
    "@app.route('/helpline')\n",
    "def helpline():\n",
    "    return render_template('helpline.html')\n",
    "\n",
    "@app.route('/twitter_analysis')\n",
    "def twitter_analysis():\n",
    "    return render_template('twitter analysis.html')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
